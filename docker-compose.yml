services:
  # Airflow (orchestrator) - pre-built image
  airflow:
    image: apache/airflow:2.5.1
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - GOOGLE_APPLICATION_CREDENTIALS=/app/config/gcp-credentials.json
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./scripts:/app/scripts
      - ./config:/app/config
      - ./Dataset:/app/Dataset
    ports:
      - "8080:8080"
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --password admin --role Admin --email admin@example.com &&
        airflow scheduler &
        airflow webserver
      "

  # Custom script services (build from local Dockerfile)
  scrape:
    build: .
    command: python /app/scripts/scrape.py
    volumes:
      - ./scripts:/app/scripts
      - ./config:/app/config
      - ./Dataset:/app/Dataset

  clean:
    build: .
    command: python /app/scripts/clean.py
    volumes:
      - ./scripts:/app/scripts
      - ./config:/app/config
      - ./Dataset:/app/Dataset
    depends_on:
      - scrape

  upload:
    build: .
    command: python /app/scripts/upload.py
    volumes:
      - ./scripts:/app/scripts
      - ./config:/app/config
      - ./Dataset:/app/Dataset
    depends_on:
      - clean

  refresh:
    build: .
    command: python /app/scripts/refresh.py
    volumes:
      - ./scripts:/app/scripts
      - ./config:/app/config
      - ./Dataset:/app/Dataset
    depends_on:
      - upload